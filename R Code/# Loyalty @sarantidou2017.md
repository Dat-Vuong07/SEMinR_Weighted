# Loyalty  @sarantidou2017

Researchers suggest that trying to explain loyalty through CS alone is not enough and that there is a need for models that will include other variables as mediators, moderators or other predictors and thus increase the explained variance (Szymanski and Henard, 2001; Kumar et al., 2013)

A lot of research in marketing attempts to find the antecedents of loyalty, and some of the significant predictors are CS, trust, communication, customer factors, and the view toward the brand (Chaudhuri and Holbrook, 2001; Ball et al., 2004; Baltas et al., 2010). However, as the marketing thinking evolves and the environment changes, some new concepts introduced in the marketing thinking are increasingly gaining interest and may be better predictors of loyalty, such as the strength of the brand, the consumer-brand relationship, and the engagement with the brand (Hollebeek, 2011; Veloutsou, 2015; Dessart et al., 2016). The above researchers suggest that cognitive and affective elements can strengthen the relationship between the brand and the customer and thus affect the strength of the brand. Thus, there is a need to investigate the relevant importance of the constructs that are recognized for a long time as predictors of loyalty and the new constructs simultaneously and in particular in contexts that are somewhat idiosyncratic, such as retailing. Consequently, any improvement in identifying the factors that affect retail loyalty could be a value to managers, researchers, and investors who use satisfaction surveys to predict behaviors and based on that allocate the company’s resources (Morgan and Rego, 2006).


# Complaint 

The second recommended change is to replace complaint behavior with complaint handling, or how well any given complaint has been resolved. 

Complaint handling should have a direct e􏰛ect on satisfaction as well as loyalty. 

Well-handled complaints should have a more positive e􏰛ect on sat- isfaction while poorly handled complaints should have a more negative e􏰛ect. 

As argued previously, this change re ̄ects the more mature nature of com- plaint management systems and the fact that the complaint behavior and resolution occurs prior to the satisfaction evaluation. 

As the problem and its handling may also be salient when repurchasing the product or service or recommending it to others, complaint handling may also have a direct e􏰛ect on loyalty. 
In Fig. 3, the complaint handling construct and its relationships are shown using dotted lines to signify that they only apply to those subset of customers who complained and could subsequently evaluate the complaint handling questions.

When the relationship is positive, the implication is that the firm is successful in turning complaining customers into loyal customer. When negative, the firm's complaint handling has managed to make a bad situation even worse ,it has contributed further to customer defection.


@fornell1996
The second determinant of overall customer satisfaction  is perceived value, or the perceived level of product quality relative to the price paid. 


Grundfos Service solutions meet my expectations
Grundfos Service is easy to get in contact with



In addition, respondents had an option to select a category of “don’t know”/“will not tell” in case of lack of knowledge and/or indifference.



PLS-SEM model assessment initially focuses on the measurement models. Examination of PLS-SEM estimates enables the researcher to evaluate the reliability and validity of the construct measures. Specifi- cally, multivariate measurement involves using several variables (i.e., multi-items) to measure a construct.

When evaluating the measurement models, we must distinguish between reflectively and formatively measured constructs (Chapter 2). The two approaches are based on different concepts and therefore require consideration of different evaluative measures.

 - Reflective measurement models are assessed on their internal consistency, reliability and validity. The specific measures include the composite relia- bility (as a means to assess the internal consistency reliability), convergent validity, and discriminant validity. The criteria for reflec- tive measurement models cannot be universally applied to formative measurement models.

 - Formative measures, the first step is to ensure content validity before collecting the data and estimating the PLS path model. After model estimation, different metrics are used to assess formative measures for convergent validity, the significance and relevance of indicator weights, and the presence of collinearity among indicators 

As implied by its name, a single-item construct (Chapter 2) is not represented by a multi-item measurement model. The relationship (i.e., the correlation) between the single indicator and the latent variable is always 1. Put differently, the single indicator and the latent variable have identical values. Thus, the criteria for the assessment of measure- ment models are not applicable to single-item constructs.

The structural model estimates are not examined until the relia- bility and validity of the constructs have been established. PLS- SEM assessment of the structural model involves the model’s ability to predict the variance in the dependent variables. Hence, after relia- bility and validity are established, the primary evaluation criteria for PLS-SEM results are the coefficients of determination (R2 values) as well as the size and significance of the path coefficients. The f 2 effect sizes, predictive relevance (Q2), and the q2 effect sizes give additional insights about quality of the PLS path model estimations

Rules of Thumb for Evaluating PLS-SEM Results

    1. Begin the evaluation process by assessing the quality of the reflective and formative measurement models 
    2. If the measurement characteristics of constructs are acceptable, continue with the assessment of the structural model results. Path estimates should be statistically significant and meaningful. Moreover, endogenous constructs in the structural model should have high levels of explained variance as expressed in high R2 values
    3. Advanced analyses that extend and differentiate initial PLS-SEM findings may be necessary to obtain a correct picture of the results

Assessment of reflective measurement models includes 
 - composite reliability to evaluate internal consistency, 
 - individual indicator reliability, and average variance extracted (AVE) to evaluate convergent validity. 

Assessment of reflective measurement models also includes discriminant validity. 

The Fornell-Larcker criterion, cross-loadings, and especially the heterotrait-monotrait (HTMT) ratio of correlations can be used to examine discriminant validity. 

Internal Consistency Reliability

The first criterion to be evaluated is typically internal consistency reliability. The traditional criterion for internal consistency is Cronbach’s alpha, which provides an estimate of the reliability based on the intercorrelations of the observed indicator variables.

Due to Cronbach’s alpha’s limitations, it is technically more appropriate to apply a different measure of internal consistency reliability, which is referred to as composite reliability. This measure of reliability takes into account the different outer loadings of the indicator variables.

The composite reliability varies between 0 and 1, with higher values indicating higher levels of reliability. It is generally interpreted in the same way as Cronbach’s alpha. Specifically, composite reliability values of 0.60 to 0.70 are acceptable in exploratory research, while in more advanced stages of research, values between 0.70 and 0.90 can be regarded as satisfactory. 

    - Values above 0.90 (and definitely above 0.95) are not desirable because they indicate that all the indicator variables are measuring the same phenomenon and are therefore not likely to be a valid measure of the construct. Specifically, such composite reliability values occur if one uses semantically redundant items by slightly rephrasing the very same question. As the use of redundant items has adverse consequences for the measures’ content validity (e.g., Rossiter, 2002) and may boost error term correlations (Drolet & Morrison, 2001; Hayduk & Littvay, 2012), researchers are advised to minimize the number of redundant indicators. 

    - Composite reliability values below 0.60 indicate a lack of internal consistency reliability.

Convergent Validity

Convergent validity is the extent to which a measure correlates positively with alternative measures of the same construct. Therefore, the items that are indicators (measures) of a specific reflective construct should converge or share a high propor- tion of variance. To evaluate convergent validity of reflective con- structs, researchers consider the outer loadings of the indicators and the average variance extracted (AVE).

Outer loadings
    - High outer loadings on a construct indicate the associated indicators have much in common, which is captured by the con- struct. The size of the outer loading is also commonly called indi- cator reliability. At a minimum, the outer loadings of all indicators should be statistically significant. Because a significant outer load- ing could still be fairly weak, a common rule of thumb is that the standardized outer loadings should be 0.708 or higher. This means that an indicator’s outer loading should be above 0.708 since that number squared (0.7082) equals 0.50. Note that in most instances, 0.70 is considered close enough to 0.708 to be acceptable.
    Researchers frequently obtain weaker outer loadings (<0.70) in social science studies, especially when newly developed scales are used (Hulland, 1999).
    Indicators with very low outer load- ings (below 0.40) should, however, always be eliminated from the construct (Bagozzi, Yi, & Philipps, 1991; Hair et al., 2011)

Average variance extracted (AVE)
    - A common measure to establish convergent validity on the con- struct level is the average variance extracted (AVE). This criterion is defined as the grand mean value of the squared loadings of the indica- tors associated with the construct (i.e., the sum of the squared load- ings divided by the number of indicators). Therefore, the AVE is equivalent to the communality of a construct. Using the same logic as that used with the individual indicators, an AVE value of 0.50 or higher indicates that, on average, the con- struct explains more than half of the variance of its indicators. Con- versely, an AVE of less than 0.50 indicates that, on average, more variance remains in the error of the items than in the variance explained by the construct.


Discriminant Validity
    - Discriminant validity is the extent to which a construct is truly distinct from other constructs by empirical standards. The cross-loadings are typically the first approach to assess the discriminant validity of the indicators. Specifically, an indicator’s outer loading on the associated construct should be greater than any of its cross-loadings (i.e., its correlation) on other constructs. The best way to assess and report cross-loadings is in a table with rows for the indicators and columns for the latent variable.
    The loadings always exceed the cross-loadings. For example, x11 loads high on its corresponding construct Y1 (0.75) but much lower on constructs Y2 (0.49) and Y3 (0.41). In this example, the analysis of cross-loadings suggests that discriminant validity has been established. 

    - The Fornell-Larcker criterion is the second approach to assessing discriminant validity. It compares the square root of the AVE values with the latent variable correlations.

Recent research that critically examined the performance of cross-loadings and the Fornell-Larcker criterion for discriminant validity assessment has found that neither approach reliably detects discriminant validity issues (Henseler et al., 2015).

As a remedy, Henseler et al. (2015) propose assessing the heterotrait-monotrait ratio (HTMT) of the correlations. In short, HTMT is the ratio of the between-trait correlations to the within- trait correlations. HTMT is the mean of all correlations of indicators across constructs measuring different constructs (i.e., the heterotrait-heteromethod correlations) relative to the (geometric) mean of the average correlations of indicators measuring the same construct (i.e., the monotrait-heteromethod correlations; for a for- mal definition of the HTMT statistic, see Henseler et al., 2015).

Technically, the HTMT approach is an estimate of what the true correlation between two constructs would be, if they were perfectly measured (i.e., if they were perfectly reliable). This true correlation is also referred to as disattenuated correlation. A disattenuated cor- relation between two constructs close to 1 indicates a lack of discri- minant validity.



Once we have confirmed that the construct measures are reliable and valid

Structural model that represents the underly- ing structural theories/concepts of the path model. Assessment of the structural model results enables you to determine the model’s capabil- ity to predict one or more target constructs.

Assessment of the structural model results,  involves examining the model’s predictive capabilities and the relationships between the constructs.

1. Examine the structural model for collinearity. The reason is that the estimation of path coefficients in the structural models is based on OLS regressions of each endogenous latent variable on its corresponding predecessor constructs. Just as in a regular multiple regression, the path coefficients might be biased if the estima- tion involves critical levels of collinearity among the predictor constructs.

The structural model is pri- marily assessed on the basis of heuristic criteria that are determined by the model’s predictive capabilities. 
The key criteria for assessing the struc- tural model in PLS-SEM are 
    - the significance of the path coefficients (Step 2)
    - the level of the R2 values (Step 3)
    - the f^2 effect size (Step 4)
    - the predictive relevance Q2 (Step 5)
    - and the q2 effect size (Step 6)

Step 1: Collinearity Assessment

    To assess collinearity, we apply the same measures as in the evalu- ation of formative measurement models (i.e., tolerance and VIF values)
    Analogous to the assessment of formative measurement models, we consider tolerance values below 0.20 (VIF value above 5) in the predictor constructs as critical levels of collinearity. If a critical level of collinearity is indicated by the tolerance or VIF guidelines, one should consider eliminating constructs, merging predictors into a single construct, or creating higher-order constructs (Chapter 8) to treat collinearity problems.

Step 2: Structural Model Path Coefficients

    After running the PLS-SEM algorithm, estimates are obtained for the structural model relationships (i.e., the path coefficients), which represent the hypothesized relationships among the constructs.
    The path coefficients have standardized values approximately between –1 and +1 (values can be smaller/larger but usually fall in between these bounds)
    Whether a coefficient is significant ultimately depends on its standard error that is obtained by means of bootstrapping. 
    The bootstrap standard error enables computing the empirical t values and p val- ues for all structural path coefficients.

    Commonly used critical values for two-tailed tests are 1.65 (significance level = 10%), 1.96 (significance level = 5%), and 2.57 (significance level = 1%).

    The bootstrap confidence interval also allows testing whether a path coefficient is significantly different from zero. The confidence interval provides information on the stability of the estimated coefficient by offering a range of plausible population values for the parameter dependent on the variation in the data and the sample size.

    If a confidence interval for an estimated path coefficient does not include zero, the hypothesis that the path equals zero is rejected, and we assume a significant effect.


    Relevance of Significant Relationships - After examining the significance of relationships, it is important to assess the relevance of significant relationships.

    The path coefficients in the structural model may be significant, but their size may be very small. Such situations often occur with large sample sizes. An analysis of the relative importance of relationships is crucial for interpreting the results and drawing conclusions since such small coefficients, even though significant, may not warrant managerial attention.

    The structural model path coefficients can be interpreted relative to one another. If one path coefficient is larger than another, its effect on the endogenous latent variable is greater.

    A one-unit change of the exogenous construct changes the endogenous construct by the size of the path coefficient when everything else (i.e., all other constructs and their path coefficients) remains constant (ceteris paribus; Hair et al., 2010). 
    If the path coefficient is statistically significant, its value indicates the extent to which the exogenous construct is associated with the endogenous construct.

Step 3: Coefficient of Determination (R2 Value)

    The most commonly used measure to evaluate the structural model is the coefficient of determination (R2 value). This coefficient is a measure of the model’s predictive power and is calculated as the squared correlation between a specific endogenous construct’s actual and predicted values.

    That is, the coefficient represents the amount of variance in the endogenous constructs explained by all of the exogenous constructs linked to it.

    Because the R2 is the squared correlation of actual and predicted val- ues and, as such, includes all the data that have been used for model estimation to judge the model’s predictive power, it represents a mea- sure of in-sample predictive power (Rigdon, 2012; Sarstedt, Ringle, Henseler, & Hair, 2014).

    As with multiple regression, the adjusted coefficient of determina- tion (R2 ) can be used as the criterion to avoid bias toward complex models. The R2 value reduces the R2 value by the number of adj explaining constructs and the sample size and thus systematically compensates for adding nonsignificant exogenous constructs merely to increase the explained variance R2.

Step 4: Effect Size f2

    The change in the R2 value when a specified exogenous construct is omitted from the model can be used to evaluate whether the omitted construct has a substantive impact on the endogenous constructs. 

    Technically, the change in the R2 values is calculated by estimating the PLS path model twice. It is estimated the first time with the exogenous latent variable included (yielding R2 ) and the second time with the exogenous latent variable excluded (yielding R2 )


Bootstrapping Procedure

PLS-SEM does not assume the data are normally distributed. Lack of normality means that parametric significance tests used in regression analyses cannot be applied to test whether coefficients such as outer weights, outer loadings, and path coefficients are significant. Instead, PLS-SEM relies on a nonparametric bootstrap procedure (Davison & Hinkley, 1997; Efron & Tibshirani, 1986) to test coefficients for their significance.

The advandtages of PLS-SEM is that it does not assume the data are normally distributed, however lack of that assumption means that parametric significance tests cannot be applied. Therefore, a nonparametric bootstrap procedure (Davison & Hinkley, 1997; Efron & Tibshirani, 1986) is used as a method to test coefficients for their significance in PLS-SEM 


Value :
         Image       Products        Service    SalesPersonnel       Delivery   Responsiveness 
         3.550          3.565          3.749          3.171          2.648          2.888 

Satisfaction :
         Image       Products        Service    SalesPersonnel       Delivery   Responsiveness      Marketing          Value 
         3.996          4.012          3.914          3.216          2.770          2.901             3.769             2.483 

Loyalty :
         Image       Products        Service    SalesPersonnel       Delivery   Responsiveness      Marketing   Satisfaction 
         3.940          3.922          3.927          3.317          2.838          3.266             3.758          3.943 

Responsiveness :
       Service       Delivery       SalesPersonnel 
         3.156          2.333          2.463 